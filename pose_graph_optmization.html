<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,900">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,700">
    <link rel="stylesheet" href="../../latex.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {
            autoNumber: "AMS",
            useLabelIds: true
          }
        },
        "HTML-CSS": {
          availableFonts: ["STIX"],
          linebreaks: { automatic: true },
          imageFont: null
        }
      });
    </script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <meta charset="UTF-8">
    <base target="_blank">
    <title>Pose Graph Optimization</title>
    <style>
        body {
            font-family: 'Lato', 'Google Sans', sans-serif;
            line-height: 1.6;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px 40px;
            font-size: 20px;
            counter-reset: figure-counter;
            text-align: justify;
        }
        h1 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            text-align: center;
            margin-bottom: 2em;
            font-size: 2.5em;
        }
        h2 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            font-size: 1.8em;
            margin-top: 1.5em;
        }
        h3 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            font-size: 1.4em;
            margin-top: 1.2em;
        }
        .figure {
            text-align: center;
            margin: 30px 0;
            width: 100%;
            counter-increment: figure-counter;
        }
        .figure img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
        .figure-caption {
            font-style: italic;
            margin-top: 15px;
            text-align: center;
            font-size: 1em;
        }
        .figure-caption::before {
            content: "Figure " counter(figure-counter) ": ";
            font-weight: bold;
            font-style: normal;
        }
        .subfigure-container {
            display: flex;
            justify-content: center;
            gap: 40px;
            margin-bottom: 20px;
            max-width: 1400px;
            margin-left: auto;
            margin-right: auto;
        }
        .subfigure {
            flex: 0 1 600px;
            text-align: center;
        }
        .subfigure img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
            min-width: 400px;
        }
        .subfigure .figure-caption {
            font-style: italic;
            margin-top: 10px;
            text-align: center;
            font-size: 1em;
        }
        .subfigure .figure-caption::before {
            content: none;
        }
        .MathJax {
            font-size: 1.1em !important;
        }
        .MathJax_Display {
            overflow-x: auto;
            overflow-y: hidden;
            margin: 1em 0;
        }
        .equation-container {
            display: table;
            width: 100%;
            margin: 1.5em 0;
        }
        .equation-content {
            display: table-cell;
            width: 100%;
        }
        .figure-label::before {
            content: "Figure " counter(figure-counter) ":";
            font-weight: bold;
            margin-right: 0.5em;
        }
        /* MathJax display styles */
        .MJXc-display {
            overflow-x: auto;
            overflow-y: hidden;
            scrollbar-width: none;
            -ms-overflow-style: none;
        }
        .MJXc-display::-webkit-scrollbar {
            width: 5px;
            height: 2px;
        }
        .MJXc-display::-webkit-scrollbar-track {
            background: transparent;
        }
        .MJXc-display::-webkit-scrollbar-thumb {
            background: #ddd;
            visibility:hidden;
        }
        .MJXc-display:hover::-webkit-scrollbar-thumb {
            visibility:visible;
        }
    </style>
</head>
<body>
<h1>Pose Graph Optimization 1</h1>
From this tutorial, we will start to explore the back-end of visual SLAM. We will start from the optimization-based methods, which is usually formulated as a pose graph optimization problem.

<h2>The sparse bundle adjustment (BA) problem</h2>
In the bundle adjustment problem, we want to optimize the camera poses and the 3D points by minimizing the reprojection error, which is denoted as,
\begin{equation}
\begin{aligned}
& \arg \min_{\mathbf{T}_{CWi}, \mathbf{X}_{Wj}} \left( \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{n}\left\| \mathbf{x}_j - \mathbf{K} \mathbf{T}_{CWi} \mathbf{X}_{Wj} \right\|_2^2 \right) \\
&= \arg \min_{\mathbf{T}_{CWi}, \mathbf{X}_{Wj}} \left( \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{n}\left\| \mathbf{x}_j - \pi (\mathbf{T}_{CWi}, \mathbf{X}_{Wj}) \right\|_2^2 \right) \\
&= \arg \min_{\mathbf{T}_{CWi}, \mathbf{X}_{Wj}} f = \arg \min_{\mathbf{T}_{CWi}, \mathbf{X}_{Wj}} \left( \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{n} \mathbf{e}_{ij}^2 \right) \\
\label{eq:reproj_error}
\end{aligned}
\end{equation}

The variables we want to optimize are the camera poses and the 3D points, which are denoted as:
\begin{equation}
\mathbf{\mathcal{X}} = [\mathbf{T}_1, \ldots, \mathbf{T}_m, \mathbf{X}_1, \ldots, \mathbf{X}_n]^\top
\end{equation}

Recall the Gaussian-Newton method for solving the non-linear least squares problem, where we linearlize the objective function $f(\mathbf{x})$, 
\begin{equation}
f(\mathbf{x} + \Delta\mathbf{x}) 
\approx f(\mathbf{x}) + \mathbf{J}(\mathbf{x})^\top \Delta\mathbf{x}
\end{equation}

and the optimal solution can be found by solving,
\begin{equation}
\Delta\mathbf{x}^* = 
\arg\min_{\Delta\mathbf{x}} 
\tfrac{1}{2}\|f(\mathbf{x}) + \mathbf{J}(\mathbf{x})^\top \Delta\mathbf{x}\|^2
\end{equation}

The optimal $\mathbf{x}$ is solved with its normal equation,
\begin{equation}
\mathbf{J}(\mathbf{x})^\top \mathbf{J}(\mathbf{x})\Delta\mathbf{x} 
= -\mathbf{J}(\mathbf{x})^\top f(\mathbf{x})
\end{equation}

\begin{equation}
\mathbf{H}\Delta\mathbf{x} = \mathbf{g}
\end{equation}

where $\mathbf{H}$ is the second-order approximation of the Hessian. <br><br>

Apply this to this BA problem, here we just $\mathbf{J}_C$ to denote the Jacobian over pose and $\mathbf{J}_P$ the Jacobian over 3D landmark points,
\begin{equation}
\begin{aligned}
\frac{1}{2}\| f(\mathbf{\mathcal{X}} + \Delta\mathbf{\mathcal{X}})\|^2 
&\approx \frac{1}{2}\sum_{i=1}^m \sum_{j=1}^n 
\|\mathbf{e}_{ij} + {\mathbf{J}_C}_{ij}\Delta\boldsymbol{\xi}_i + {\mathbf{J}_P}_{ij}\Delta\mathbf{X}_{j}\|^2 \\
&= \frac{1}{2}\|\mathbf{e} + \mathbf{J}_C\Delta \mathbf{\mathcal{X}_c} + \mathbf{J}^X\Delta\mathbf{\mathcal{X}_p}\|^2
\end{aligned}
\end{equation}

\begin{equation}
\mathbf{H}\Delta\mathbf{\mathcal{X}} = \mathbf{g}
\end{equation}

The Jacobian which combines $\mathbf{J}_C$ and $\mathbf{J}_P$ is denoted as,
\begin{equation}
\mathbf{J} = [\mathbf{J}_C, \mathbf{J}_P]^\top
\end{equation}

And and approximated Hessian matrix is,
\begin{equation}
\begin{aligned}
\mathbf{H} = \mathbf{J}^\top \mathbf{J} &= 
\begin{bmatrix}
{\mathbf{J}_C}^\top \mathbf{J}_C & {\mathbf{J}_C}^\top \mathbf{J}_P \\
{\mathbf{J}_P}^\top \mathbf{J}_C & {\mathbf{J}_P}^\top \mathbf{J}_P
\end{bmatrix} \\
&= \begin{bmatrix}
\mathbf{H}_{CC} & \mathbf{H}_{CP} \\
\mathbf{H}_{PC} & \mathbf{H}_{PP}
\end{bmatrix}
\end{aligned}
\end{equation}

<h2>Sparsity of the Hessian structure</h2>
In visual SLAM, the local observability between camera poses and 3D points makes the Jacobian of the reprojection error term $\mathbf{e}$ w.r.t $\mathbf{\mathcal{X}}$ sparse. Think about a camera moving in a scene, only a subset of the 3D point map is observed by a subset of camera pose trajectory. So consider error term $\mathbf{e}_{ij}$ at the $i$-th pose and $j$-th 3D point, the Jacobian $\mathbf{J}_{ij}(\mathbf{\mathcal{X}})$ is derived as,

\begin{equation}
\mathbf{J}_{ij}(\mathbf{\mathcal{X}}) = 
[\mathbf{0}_{2\times6}, \ldots, 
\tfrac{\partial \mathbf{e}_{ij}}{\partial \mathbf{T}_i}, 
\mathbf{0}_{2\times6}, \ldots, 
\tfrac{\partial \mathbf{e}_{ij}}{\partial \mathbf{p}_j}, 
\mathbf{0}_{2\times3}, \ldots]^\top
\end{equation}

Thus the Hessian matrix $\mathbf{H}$ is sparse, which can be written as the summation of the Jacobian of each error term,
\begin{equation}
\mathbf{H} = \sum_{i,j} \mathbf{J}_{ij}^\top \mathbf{J}_{ij}
\end{equation}

<h3>Hessian sparsity example</h3>
We will use a concrete example to illustrate the sparsity of the Hessian matrix. Consider the following error term,
\begin{equation}
\frac{1}{2}\sum \|\mathbf{e}_{ij}\|^2 
= \tfrac{1}{2}(\|\mathbf{e}_{11}\|^2+\|\mathbf{e}_{12}\|^2+\|\mathbf{e}_{13}\|^2+
\|\mathbf{e}_{14}\|^2+\|\mathbf{e}_{23}\|^2+\|\mathbf{e}_{25}\|^2+\|\mathbf{e}_{26}\|^2)
\end{equation}

\begin{equation}
\mathbf{J}_{11} =
\frac{\partial \mathbf{e}_{11}}{\partial \mathbf{x}} = 
( \tfrac{\partial \mathbf{e}_{11}}{\partial \boldsymbol{\xi}_1},
\mathbf{0}_{2\times6}, 
\tfrac{\partial \mathbf{e}_{11}}{\partial \mathbf{p}_1},
\mathbf{0}_{2\times3}, \ldots )
\end{equation}


<h2>Schur Complement</h2>
\begin{equation}
\begin{bmatrix}
\mathbf{B} & \mathbf{J}_P \\
{\mathbf{J}_P}^\top & \mathbf{C}
\end{bmatrix}
\begin{bmatrix}
\Delta\mathbf{x}_c \\ \Delta\mathbf{x}_p
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{v} \\ \mathbf{w}
\end{bmatrix}
\end{equation}

\begin{equation}
\begin{bmatrix}
\mathbf{I} & - \mathbf{J}_P \mathbf{C}^{-1} \\
\mathbf{0} & \mathbf{I}
\end{bmatrix}
\begin{bmatrix}
\mathbf{B} & \mathbf{J}_P \\
{\mathbf{J}_P}^\top & \mathbf{C}
\end{bmatrix}
\begin{bmatrix}
\Delta\mathbf{x}_c \\ \Delta\mathbf{x}_p
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{I} & -\mathbf{J}_P \mathbf{C}^{-1} \\
\mathbf{0} & \mathbf{I}
\end{bmatrix}
\begin{bmatrix}
\mathbf{v} \\ \mathbf{w}
\end{bmatrix}
\end{equation}

\begin{equation}
\begin{bmatrix}
\mathbf{B} - \mathbf{J}_P \mathbf{C}^{-1} {\mathbf{J}_P}^\top & \mathbf{0} \\
{\mathbf{J}_P}^\top & \mathbf{C}
\end{bmatrix}
\begin{bmatrix}
\Delta\mathbf{x}_c \\ \Delta\mathbf{x}_p
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{v} - \mathbf{J}_P \mathbf{C}^{-1} \mathbf{w} \\ \mathbf{w}
\end{bmatrix}
\end{equation}

\begin{equation}
[\mathbf{B} - \mathbf{J}_P \mathbf{C}^{-1} {\mathbf{J}_P}^\top] \Delta\mathbf{x}_c 
= \mathbf{v} - \mathbf{J}_P \mathbf{C}^{-1} \mathbf{w}
\end{equation}