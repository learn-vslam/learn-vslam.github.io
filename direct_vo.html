<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400,900">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,700">
    <link rel="stylesheet" href="../../latex.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {
            autoNumber: "AMS",
            useLabelIds: true
          }
        },
        "HTML-CSS": {
          availableFonts: ["STIX"],
          linebreaks: { automatic: true },
          imageFont: null
        }
      });
    </script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <meta charset="UTF-8">
    <base target="_blank">
    <title>Direct Visual Odometry</title>
    <style>
        body {
            font-family: 'Lato', 'Google Sans', sans-serif;
            line-height: 1.6;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px 40px;
            font-size: 20px;
            counter-reset: figure-counter;
            text-align: justify;
        }
        h1 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            text-align: center;
            margin-bottom: 2em;
            font-size: 2.5em;
        }
        h2 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            font-size: 1.8em;
            margin-top: 1.5em;
        }
        h3 {
            color: #333;
            font-family: 'Google Sans', sans-serif;
            font-size: 1.4em;
            margin-top: 1.2em;
        }
        .figure {
            text-align: center;
            margin: 30px 0;
            width: 100%;
            counter-increment: figure-counter;
        }
        .figure img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
        .figure-caption {
            font-style: italic;
            margin-top: 15px;
            text-align: center;
            font-size: 1em;
        }
        .figure-caption::before {
            content: "Figure " counter(figure-counter) ": ";
            font-weight: bold;
            font-style: normal;
        }
        .subfigure-container {
            display: flex;
            justify-content: center;
            gap: 40px;
            margin-bottom: 20px;
            max-width: 1400px;
            margin-left: auto;
            margin-right: auto;
        }
        .subfigure {
            flex: 0 1 600px;
            text-align: center;
        }
        .subfigure img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
            min-width: 400px;
        }
        .subfigure .figure-caption {
            font-style: italic;
            margin-top: 10px;
            text-align: center;
            font-size: 1em;
        }
        .subfigure .figure-caption::before {
            content: none;
        }
        .MathJax {
            font-size: 1.1em !important;
        }
        .MathJax_Display {
            overflow-x: auto;
            overflow-y: hidden;
            margin: 1em 0;
        }
        .equation-container {
            display: table;
            width: 100%;
            margin: 1.5em 0;
        }
        .equation-content {
            display: table-cell;
            width: 100%;
        }
        .figure-label::before {
            content: "Figure " counter(figure-counter) ":";
            font-weight: bold;
            margin-right: 0.5em;
        }
        /* MathJax display styles */
        .MJXc-display {
            overflow-x: auto;
            overflow-y: hidden;
            scrollbar-width: none;
            -ms-overflow-style: none;
        }
        .MJXc-display::-webkit-scrollbar {
            width: 5px;
            height: 2px;
        }
        .MJXc-display::-webkit-scrollbar-track {
            background: transparent;
        }
        .MJXc-display::-webkit-scrollbar-thumb {
            background: #ddd;
            visibility:hidden;
        }
        .MJXc-display:hover::-webkit-scrollbar-thumb {
            visibility:visible;
        }
    </style>
</head>
<body>
<h1>Direct Visual Odometry</h1>

<h2>Sparse Direct Visual Odometry</h2>
The previous introduced feature-based visual odometry methods are mostly always sparse due to the extraction of keypoint and point features in images. In sparse direct visual odometry, we also track sparse keypoints in images, but instead of using features, we use the pixel intensity values directly. This will apply the sparse optical flow we introcued previously, e.g. Lucas-Kanade method.

<h2>Dense Direct Visual Odometry</h2>
In a dense direct visual odometry, we ultilize the pixel intensity in the entire image. The first steps of direct VO is to have an initial guess of current reference depth map $\hat{Z}$ and camera pose $\hat{\mathbf{T}} = [\hat{\mathbf{R}},\hat{\mathbf{t}}]$. Then we warp the reference image to the target frame using the estimated camera pose and depth map, and compute the photometric loss between the warped image and the target image, to optimize the camera pose and depth map.

\begin{equation}
\mathbf{X}_W = [\,X,\;Y,\;Z\,]^{\top}
\end{equation}

\begin{equation}
\tilde{\mathbf{x}}_{\mathrm{im,ref}} = \frac{1}{Z}\,\mathbf{K}\,\mathbf{X}_W
\end{equation}

\begin{equation}
\mathbf{X}_W = \hat{Z}\,\mathbf{K}^{-1}\,\tilde{\mathbf{x}}_{\mathrm{im,ref}}
\end{equation}

\begin{equation}
\tilde{\mathbf{x}}_{\mathrm{im,warp}} =
\mathbf{K}\,[\,\hat{\mathbf{R}}\mid \hat{\mathbf{t}}\,]\,
\hat{Z}\,\mathbf{K}^{-1}\,\tilde{\mathbf{x}}_{\mathrm{im,ref}}
\end{equation}

This is an optimization problem to optimize the $\textit{photometric loss}$, which is then formulated as,
\begin{equation}
\min_{\mathbf{T}, \hat{Z}} J(\mathbf{T}, \hat{Z})  = \frac{1}{HW}\sum_{i=1}^{HW}
\left|\,I_{\mathrm{target}}(i) - I_{\mathrm{warp}}(i)\,\right\|^2
\end{equation}

where $I$ denotes the pixel intensity of the image, $H$ and $W$ are the height and width of the image, respectively.

For RGBD and stereo camera rig, it is easy to direct compute the depth map $\hat{Z}$ from the depth sensor. But for monocular cameras, the depth needs to be initialized from a random guess, which makes the optimization more challenging. <br>

Let's first derive the gradient of the optimization objective with respect to the depth map $\hat{Z}$. We leave the gradient with respect to the camera pose $\hat{\mathbf{T}}$ for the next section.


Define the error term as,
\begin{equation}
e = I_{\mathrm{target}}(i) - I_{\mathrm{warp}}(i)
\end{equation}

\begin{equation}
\begin{aligned}
\frac{\partial e}{\partial \hat{Z}} &= - \frac{\partial I_{\mathrm{warp}}}{\partial \hat{Z}} = - \frac{\partial I_{\mathrm{warp}}}{\partial \mathbf{x}_{warp}}  \frac{\partial \mathbf{x}_{warp}}{\partial \hat{Z}} \\
&= - \frac{\partial I_{\mathrm{warp}}}{\partial \mathbf{x}_{warp}} \left(\mathbf{K}\,[\,\hat{\mathbf{R}}\mid \hat{\mathbf{t}}\,]\,
\,\mathbf{K}^{-1}\, \mathbf{x}_{\mathrm{ref}} \right)
\end{aligned}
\end{equation}

Typical method of dense direct methods are LSD-SLAM and DSO. And in these methods only chunks of images which have high gradients will be used, such as corners and edges.

<h2>Sparse Direct Visual Odometry</h2>
In sparse direct methods, we also optimize the camera pose to minimize the photometric error, but insteand of using the whole image or a alrge chunk of image, we only use points from the keypoint and optical flow tracking (e.g. KLT). Here the photometric error is the brightness error of the two pixels of $\mathbf{X}$ projrected to two images:

where,
\begin{equation}
\mathbf{x}_1 =
\begin{bmatrix}
u_1 \\ v_1 \\ 1
\end{bmatrix}
= \frac{1}{Z_1} \mathbf{K}\mathbf{X}, 
\qquad
\mathbf{x}_2 =
\begin{bmatrix}
u_2 \\ v_2 \\ 1
\end{bmatrix}
= \frac{1}{Z_2} \mathbf{K} (\mathbf{T}\mathbf{X}).
\end{equation}

Note that $e$ is a scalar here.  
Similarly, the optimization is with respect to the $L_2$ norm of the error, taking the unweighted form for now, as:

\begin{equation}
\min_{\mathbf{T}} J(\mathbf{T}) = \| e \|^2.
\end{equation}

The optimization is still based on the \textbf{constant brightness assumption}.  
We assume that the grayscale of a spatial point imaged at various viewing points is constant.  
If we have many (for example, $N$) space points $\mathbf{X}_i$, then the whole camera pose estimation problem becomes:

\begin{equation}
\min_{\mathbf{T}} J(\mathbf{T}) = \sum_{i=1}^{N} e_i^{\top} e_i, 
\quad e_i = I_1(\mathbf{x}_{1,i}) - I_2(\mathbf{x}_{2,i}).
\end{equation}

The variable to be optimized here is the camera pose $\mathbf{T}$, instead of the motion of each feature point in the optical flow.  
To solve this optimization problem, we are concerned about how the error $e$ changes with the camera pose $\mathbf{T}$,  
and we need to analyze their derivative relationship.  
First, define two intermediate variables:
\begin{equation}
\mathbf{X}_C = \mathbf{T}\mathbf{X}_W, \qquad
\mathbf{x} = \frac{1}{Z_2}\mathbf{K}\mathbf{X}_C.
\end{equation}
  
Consider the left perturbation model of Lie algebra, using the first-order Taylor expansion:
\begin{equation}
e(\mathbf{T}) = I_1(\mathbf{x}_1) - I_2(\mathbf{x}_2).
\end{equation}

Then we get:

\begin{equation}
\frac{\partial e}{\partial \mathbf{T}}
= - \frac{\partial I_2}{\partial \mathbf{x}}
\frac{\partial \mathbf{x}}{\partial \mathbf{X}_C}
\frac{\partial \mathbf{X}_C}{\partial \delta \mathbf{\xi}},
\end{equation}

where $\delta \mathbf{\xi}$ is the left disturbance of $\mathbf{T}$, where

$\frac{\partial I_2}{\partial \mathbf{x}}$ is the grayscale gradient at pixel $\mathbf{x}$.

$\frac{\partial \mathbf{x}}{\partial \mathbf{X}_C}$ is the derivative of the projection equation with respect to the three-dimensional point in the camera frame. 

Let $\mathbf{X}_C = [X, Y, Z]^{\top}$, according to Chapter 3, the derivative is:


\begin{equation}
\frac{\partial \mathbf{x}}{\partial \mathbf{X}_C} =
\begin{bmatrix}
\frac{f_x}{Z} & 0 & -\frac{f_x X}{Z^2} \\
0 & \frac{f_y}{Z} & -\frac{f_y Y}{Z^2}
\end{bmatrix}.
\end{equation}

$\frac{\partial \mathbf{X}_C}{\partial \delta \mathbf{\xi}}$ is the derivative of the transformed three-dimensional point with respect to the transformation, which was introduced before as,

\begin{equation}
\frac{\partial \mathbf{X}_C}{\partial \delta \mathbf{\xi}} =
[\mathbf{I}, -\mathbf{X}_C^{\wedge}].
\end{equation}

In practice, the last two items are only related to the three-dimensional point $\mathbf{X}_C$, which is irrelevant to the image.  
We often combine them together:

\begin{equation}
\frac{\partial \mathbf{x}}{\partial \delta \mathbf{\xi}} =
\begin{bmatrix}
\frac{f_x}{Z} & 0 & -\frac{f_x X}{Z^2} & -\frac{f_x X Y}{Z^2} & f_x + \frac{f_x X^2}{Z^2} & -\frac{f_x Y}{Z} \\
0 & \frac{f_y}{Z} & -\frac{f_y Y}{Z^2} & -f_y - \frac{f_y Y^2}{Z^2} & \frac{f_y X Y}{Z^2} & \frac{f_y X}{Z}
\end{bmatrix}.
\end{equation}

This $2 \times 6$ matrix also appeared in the previous post. Therefore, we derive the Jacobian of residual with respect to Lie algebra as:

\begin{equation}
\mathbf{J} = - \frac{\partial I_2}{\partial \mathbf{x}}
\frac{\partial \mathbf{x}}{\partial \delta \mathbf{\xi}}.
\end{equation}

This Jacobian is used in to gradient-based optimization problem to update the camera pose. From the above equation we can see that that gradient is 0 when the pixel gradient is 0, which means feature-less regions will have 0 gradient, this explain again why LSD-SLAM and DSO choose regions with rich textures. But in sparse direct method, the pixels are computed from keypoints detections. One typical algorithm of sparse direct method is SVO.
